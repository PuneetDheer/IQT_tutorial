{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Quality Transfer (IQT) in MRI with Deep Neural Networks\n",
    "\n",
    "- MediCSS Project\n",
    "- 03/07/2019\n",
    "- v1.1\n",
    "- Led by Harry Hongxiang Lin and Ryutaro Tanno\n",
    "- Language: Python+Keras+Tensorflow\n",
    "\n",
    "This notebook is a demo for IQT using deep learning. IQT predicts cross-plane voxels along slice thickness direction by learning a super-resolution deep neural network from low/high-resolution pair data. These pre-trained networks were trained by the Human Connetome Project (HCP) dataset and are already available in the project folder.\n",
    "\n",
    "The project aims to do super-resolution study on MR images. You will gain more practical knowledge of deep learning, especially on:\n",
    "- Understanding a general structure of pipeline for a deep learning task: data preprocessing-training-test-evaluation;\n",
    "- Apply external datasets to the pre-trained networks;\n",
    "- Visualise and evaluate the neural network in order to have some intuitive for deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### Material\n",
    "1. [Provided] Human Connectome Project dataset: http://www.humanconnectomeproject.org/ .\n",
    "2. Pre-trained models: 3D SR U-net `srunet16_16_2_nf4` and Anisotropic U-net `anisounet16_16_2_nf4`.\n",
    "\n",
    "### Config `config.py`\n",
    "\n",
    "Configurate `config.py` in the IQT project folder:\n",
    "1. In `general_configuration`, substitute `<YOUR HOME DIRECTORY>` in `dataset_path` and `base_path` with your home directory path. For example, here is my configuration:\n",
    "    `'dataset_path' : '/home/harrylin/'` and `'base_path' : '/home/harrylin/tutorial_result'`.\n",
    "2. Put the pretrained models, `srunet16_16_2_nf4` and `anisounet16_16_2_nf4`, into the `base_path`. Then set `'job_name' : 'srunet16_16_2_nf4'` or `'job_name' : 'anisounet16_16_2_nf4'`.\n",
    "3. [Done] Set `dataset_info` for the new including dataset. An example for `HCP-Wu-Minn-Contrast` dataset is given.\n",
    "4. In `training_configuration`, choose `approach` and `dataset` for training/test. The alternatives for `approach`: `SRUnet` and `AnisoUnet` corresponding to the pretrained models `'srunet16_16_2_nf4'` and `'anisounet16_16_2_nf4'`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "- The module loads the technical configuration on dataset and neural networks.\n",
    "- Create folders for placing results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import general_configuration as gen_conf\n",
    "from config import training_configuration as train_conf\n",
    "from workflow.data_preparation import data_preparation\n",
    "\n",
    "# pass arguments to jupyter notebook\n",
    "import sys\n",
    "sys.argv = ['main.py', '--gpu', '0']\n",
    "\n",
    "# data preparation\n",
    "opt, gen_conf, train_conf = data_preparation(gen_conf, train_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data simulation\n",
    "- Downsample HCP dataset\n",
    "- The simulated downsampling data will be saved in the folder of each subject `<dataset_path>/<path>/subject...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample HCP data with 1D Gaussian filter.\n",
      "Processing '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/202719/T1w/T1w_acpc_dc_restore_brain_sim036T_ds6_gap2_groundtruth.nii'\n",
      "Save to '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/202719/T1w/T1w_acpc_dc_restore_brain_procin.nii'\n",
      "Processing '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/204218/T1w/T1w_acpc_dc_restore_brain_sim036T_ds6_gap2_groundtruth.nii'\n",
      "Save to '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/204218/T1w/T1w_acpc_dc_restore_brain_procin.nii'\n",
      "Processing '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/200210/T1w/T1w_acpc_dc_restore_brain_sim036T_ds6_gap2_groundtruth.nii'\n",
      "Save to '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/200210/T1w/T1w_acpc_dc_restore_brain_procin.nii'\n",
      "Processing '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/202113/T1w/T1w_acpc_dc_restore_brain_sim036T_ds6_gap2_groundtruth.nii'\n",
      "Save to '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/202113/T1w/T1w_acpc_dc_restore_brain_procin.nii'\n",
      "Processing '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/201414/T1w/T1w_acpc_dc_restore_brain_sim036T_ds6_gap2_groundtruth.nii'\n",
      "Save to '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/201414/T1w/T1w_acpc_dc_restore_brain_procin.nii'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.preprocessing_util import preproc_dataset\n",
    "preproc_dataset(gen_conf, train_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Visualize the downsampled MRI images\n",
    "\n",
    "Please select one subject from the training set and visualize one downsampled image (input) together with its original image (output) on axial/coronal/sagittal views. Suggest using Python libs: `nibabel` (https://nipy.org/nibabel/coordinate_systems.html) `matplotlib` (https://matplotlib.org/gallery/index.html) to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/200008/T1w/T1w_acpc_dc_restore_brain.nii'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-217fe1544ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mproc_img_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/200008/T1w/T1w_acpc_dc_restore_brain_procin.nii'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgt_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_img_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mproc_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc_img_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongxianglin/anaconda2/envs/pfcnn/lib/python2.7/site-packages/nibabel/loadsave.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     '''\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0msniff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_klass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_image_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/200008/T1w/T1w_acpc_dc_restore_brain.nii'"
     ]
    }
   ],
   "source": [
    "## Sample answer.\n",
    "\n",
    "# load the subject 200008\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# image file paths\n",
    "## gt=ground truth, proc = pre-processed\n",
    "gt_img_path = '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/200008/T1w/T1w_acpc_dc_restore_brain.nii'\n",
    "proc_img_path = '/Users/hongxianglin/document/ucl_coding/P5_mri_image/HCP/200008/T1w/T1w_acpc_dc_restore_brain_procin.nii'\n",
    "\n",
    "gt_img = nib.load(gt_img_path).get_data()\n",
    "proc_img = nib.load(proc_img_path).get_data()\n",
    "\n",
    "# Plot images in a 2x3 grid. Cross-sectional views by row w/o downsampling by column.\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(10*2, 10*2),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "fig.subplots_adjust(left=0.03, right=0.97, hspace=0.05, wspace=0.05)\n",
    "\n",
    "## Intersection of 3 viewing planes (axial/coronal/sagittal) \n",
    "# intersection coordinate at original image\n",
    "gt_intersect = [150, 150, 128]\n",
    "# sparse scale\n",
    "sparse_scale = gen_conf['dataset_info']['HCP-Wu-Minn-Contrast']['sparse_scale']\n",
    "apsect_ratio_scale = np.prod(sparse_scale)/np.array(sparse_scale)\n",
    "# intersection coordinate at processed image\n",
    "proc_intersect = np.array(gt_intersect)/np.array(sparse_scale)\n",
    "\n",
    "for idx, ax in enumerate(axs):\n",
    "    # initialisation\n",
    "    gt_coord = [slice(None), slice(None), slice(None)]\n",
    "    proc_coord = [slice(None), slice(None), slice(None)]\n",
    "    \n",
    "    # \n",
    "    gt_coord[idx] = slice(gt_intersect[idx], gt_intersect[idx]+1, 1)\n",
    "    proc_coord[idx] = slice(proc_intersect[idx], proc_intersect[idx]+1, 1)\n",
    "    \n",
    "    gt_reduced_img = np.squeeze(org_img[org_coord])\n",
    "    ax[0].imshow(org_reduced_img.T, interpolation=None, cmap='gray', aspect=1, origin='lower')\n",
    "    \n",
    "    proc_reduced_img = np.squeeze(proc_img[proc_coord])\n",
    "    ax[1].imshow(proc_reduced_img.T, interpolation=None, cmap='gray', aspect=apsect_ratio_scale[idx], origin='lower')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test stage\n",
    "\n",
    "We provide a SRU-net pre-trained from the Human Connectome Project (HCP) dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing ... load data, mean, std and model...\n",
      "/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/tutorial_result/srunet16_16_2_nf4/models/HCP-Wu-Minn-Contrast/1-SRUnet-3-(32, 32, 4)-(16, 16, 2)_mean.npz\n",
      "/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/tutorial_result/srunet16_16_2_nf4/models/HCP-Wu-Minn-Contrast/1-SRUnet-3-(32, 32, 4)-(16, 16, 2)_std.npz\n",
      "/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/tutorial_result/srunet16_16_2_nf4/models/HCP-Wu-Minn-Contrast/1-SRUnet-3-(32, 32, 4)-(16, 16, 2).h5\n",
      "Test model ...\n",
      "(5780, 1, 32, 32, 4)\n",
      "5780/5780 [==============================] - 5675s 982ms/step\n",
      "(5780, 1, 32, 32, 32)\n",
      "Reconstructing ...\n",
      "/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/tutorial_result/srunet16_16_2_nf4/result/HCP-Wu-Minn-Contrast/202113_T1w-SRUnet-3-(32, 32, 4)-(16, 16, 2).nii\n",
      "Save file at /Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/tutorial_result/srunet16_16_2_nf4/result/HCP-Wu-Minn-Contrast/202113_T1w-SRUnet-3-(32, 32, 4)-(16, 16, 2).nii\n",
      "(5780, 1, 32, 32, 4)\n",
      "2368/5780 [===========>..................] - ETA: 1:41:39"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-648cf79b3aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/IQT_tutorial/workflow/test.pyc\u001b[0m in \u001b[0;36mtesting\u001b[0;34m(gen_conf, test_conf, train_conf)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test model ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m## test and save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtest_model_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# comment cauz' debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;31m# test_model(gen_conf, test_conf, input_data, model) # comment cauz' debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# test_model_2(gen_conf, test_conf, input_data) # debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/IQT_tutorial/workflow/test.pyc\u001b[0m in \u001b[0;36mtest_model_3\u001b[0;34m(gen_conf, test_conf, input_data, model, mean, std)\u001b[0m\n\u001b[1;32m     76\u001b[0m         recon_im = model.predict(x_test,\n\u001b[1;32m     77\u001b[0m                                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                                  verbose=test_conf['verbose'])\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;31m# de-normalisation before prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mrecon_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenormalise_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_modalities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongxianglin/anaconda2/envs/pfcnn/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1170\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/Users/hongxianglin/anaconda2/envs/pfcnn/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongxianglin/anaconda2/envs/pfcnn/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongxianglin/anaconda2/envs/pfcnn/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongxianglin/anaconda2/envs/pfcnn/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from workflow.test import testing\n",
    "\n",
    "model = testing(gen_conf, train_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignments:\n",
    "\n",
    "1. Show summary of networks, which is saved in the variable `model` (Hint: Using `model.summary()` https://keras.io/models/about-keras-models/).\n",
    "2. Visualise the activation for each layer (Hint: https://keras.io/examples/conv_filter_visualization/).\n",
    "3. Use other datasets (e.g. HBN, IBSR) for predicting the network outputs.\n",
    "\n",
    "HBN: Child Mind Institute Healthy Brain Network http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/index.html\n",
    "\n",
    "IBSR: Internet Brain Segmentation Repository https://www.nitrc.org/projects/ibsr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluation metrics:\n",
    "1. PSNR: Peak Signal-to-Noise Ratio\n",
    "2. SSIM: Structural Similarity Index\n",
    "3. RMSE: Root Mean Squared Error\n",
    "\n",
    "### Assigments:\n",
    "1. Look at the evaluation result under `</task_name/>/evaluation/stats_brain.csv` and compare results from the different networks.\n",
    "2. Read the reference on SSIM, https://www.cns.nyu.edu/pub/lcv/wang03-preprint.pdf, and intuitively and/or theoretically explain if this index is suitable to MR image quality assessment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/tutorial_result/srunet16_16_2_nf4/result/HCP-Wu-Minn-Contrast/202113_T1w-SRUnet-3-(32, 32, 4)-(16, 16, 2).nii\n",
      "/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/tutorial_result/srunet16_16_2_nf4/result/HCP-Wu-Minn-Contrast/201414_T1w-SRUnet-3-(32, 32, 4)-(16, 16, 2).nii\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: '/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/tutorial_result/srunet16_16_2_nf4/result/HCP-Wu-Minn-Contrast/201414_T1w-SRUnet-3-(32, 32, 4)-(16, 16, 2).nii'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-761a0491f9a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/IQT_tutorial/workflow/evaluation.py\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(gen_conf, test_conf)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/IQT_tutorial/utils/image_evaluation.py\u001b[0m in \u001b[0;36mimage_evaluation\u001b[0;34m(gen_conf, test_conf)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape : (subject, modality, mri_shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mim_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_result_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_conf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shape : (subject, modality, mri_shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# compare image and get stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/IQT_tutorial/utils/ioutils.py\u001b[0m in \u001b[0;36mread_result_volume\u001b[0;34m(gen_conf, test_conf)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'HCP-Wu-Minn-Contrast'\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mread_result_volume_HCPWuMinnContrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m     \u001b[0;31m##  todo: template for the other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;31m# elif dataset == 'MICCAI2012' :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/IQT_tutorial/utils/ioutils.py\u001b[0m in \u001b[0;36mread_result_volume_HCPWuMinnContrast\u001b[0;34m(gen_conf, test_conf)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'extraction_step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 dataset_info['format'])\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0mout_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/IQT_tutorial/utils/ioutils.py\u001b[0m in \u001b[0;36mread_volume\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mread_volume_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_volume_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/IQT_tutorial/utils/ioutils.py\u001b[0m in \u001b[0;36mread_volume_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_volume_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m def generate_output_filename(\n",
      "\u001b[0;32m/Users/hongxianglin/anaconda2/envs/pfcnn/lib/python2.7/site-packages/nibabel/loadsave.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     '''\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0msniff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_klass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_image_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/Users/hongxianglin/document/ucl_coding/P3_IQT_Unet/tutorial_result/srunet16_16_2_nf4/result/HCP-Wu-Minn-Contrast/201414_T1w-SRUnet-3-(32, 32, 4)-(16, 16, 2).nii'"
     ]
    }
   ],
   "source": [
    "from workflow.evaluation import evaluation\n",
    "\n",
    "evaluation(gen_conf, train_conf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
