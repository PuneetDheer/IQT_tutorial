{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Quality Transfer (IQT) in MRI with Deep Neural Networks\n",
    "\n",
    "- MediCSS Project\n",
    "- 06/07/2020 v1.2\n",
    "- Project leads: Harry Hongxiang Lin, Matteo Figini\n",
    "- Acknowledgement: Ryutaro Tanno (Microsoft Research Cambridge)\n",
    "- Language: Python+Keras+Tensorflow\n",
    "\n",
    "History:\n",
    "- v1.2: Simplify the installation procedure.\n",
    "- v1.1.1: Fix bugs on coding-style transfer from Python 2 to 3.\n",
    "\n",
    "This notebook provides a demo on IQT using deep learning. IQT can enhance resolution on slice thickness direction by learning a upsampling deep neural network from low- and high-resolution paired data. Human Connetome Project (HCP) dataset will be provided for evaluating the effectiveness of the algorithm.\n",
    "\n",
    "In this project, we expect to deliver practical knowledge of deep learning, especially on:\n",
    "- Understanding a general structure of pipeline for a deep learning task: data preprocessing-training-test-evaluation;\n",
    "- Apply external datasets to the trained networks;\n",
    "- Visualise and evaluate the neural network in order to have some intuitions about deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### Material [Provide by request]\n",
    "1. Dataset [Human Connectome Project dataset](http://www.humanconnectomeproject.org/): 5 processed subjects.\n",
    "2. Pre-trained models: 3D SR U-net `srunet16_16_2_nf4` and Anisotropic U-net `anisounet16_16_2_nf4`.\n",
    "\n",
    "### Configure `config.py`\n",
    "\n",
    "Configure `config.py` under the IQT project folder `IQT_tutorial`:\n",
    "1. In `general_configuration`, substitute `<YOUR HOME DIRECTORY>` in `dataset_path` and `base_path` with your home directory path. For example, here is my setting:\n",
    "    `'dataset_path' : '/home/harrylin/'` and `'base_path' : '/home/harrylin/tutorial_result'`.\n",
    "2. Put the pretrained models, `srunet16_16_2_nf4` and `anisounet16_16_2_nf4`, into the `base_path`. Then set `'job_name' : 'srunet16_16_2_nf4'` or `'job_name' : 'anisounet16_16_2_nf4'`.\n",
    "3. [Done] Set `dataset_info` for the new including dataset. An example for `HCP-Wu-Minn-Contrast` dataset is given.\n",
    "4. In `training_configuration`, choose `approach` and `dataset` for training/test. The alternatives for `approach`: `SRUnet` and `AnisoUnet` corresponding to the pretrained models `'srunet16_16_2_nf4'` and `'anisounet16_16_2_nf4'`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "- The module loads the technical configuration on dataset and neural networks.\n",
    "- Create folders for saving results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import general_configuration as gen_conf\n",
    "from config import training_configuration as train_conf\n",
    "from workflow.data_preparation import data_preparation\n",
    "\n",
    "# pass arguments to jupyter notebook\n",
    "import sys\n",
    "sys.argv = ['main.py', '--gpu', '0']\n",
    "\n",
    "# data preparation\n",
    "opt, gen_conf, train_conf = data_preparation(gen_conf, train_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data simulation\n",
    "- Downsample HCP dataset\n",
    "- The simulated downsampling data will be saved in the folder of each subject `<dataset_path>/<path>/subject...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample HCP data with 1D Gaussian filter.\n",
      "Processing '/cs/student/msc/misc/2019/ucact21/hcp/HCP/214019/T1w_acpc_dc_restore_brain.nii'\n",
      "Save to '/cs/student/msc/misc/2019/ucact21/hcp/HCP/214019/T1w_acpc_dc_restore_brain_procin.nii'\n",
      "Processing '/cs/student/msc/misc/2019/ucact21/hcp/HCP/214221/T1w_acpc_dc_restore_brain.nii'\n",
      "Save to '/cs/student/msc/misc/2019/ucact21/hcp/HCP/214221/T1w_acpc_dc_restore_brain_procin.nii'\n",
      "Processing '/cs/student/msc/misc/2019/ucact21/hcp/HCP/214423/T1w_acpc_dc_restore_brain.nii'\n",
      "Save to '/cs/student/msc/misc/2019/ucact21/hcp/HCP/214423/T1w_acpc_dc_restore_brain_procin.nii'\n",
      "Processing '/cs/student/msc/misc/2019/ucact21/hcp/HCP/214524/T1w_acpc_dc_restore_brain.nii'\n",
      "Save to '/cs/student/msc/misc/2019/ucact21/hcp/HCP/214524/T1w_acpc_dc_restore_brain_procin.nii'\n",
      "Processing '/cs/student/msc/misc/2019/ucact21/hcp/HCP/214625/T1w_acpc_dc_restore_brain.nii'\n",
      "Save to '/cs/student/msc/misc/2019/ucact21/hcp/HCP/214625/T1w_acpc_dc_restore_brain_procin.nii'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.preprocessing_util import preproc_dataset\n",
    "preproc_dataset(gen_conf, train_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Visualize the downsampled MRI images\n",
    "\n",
    "Please select one subject from the training set and visualize one downsampled image (input) together with its original image (output) on axial/coronal/sagittal views. Suggest using Python libs: `nibabel` (https://nipy.org/nibabel/coordinate_systems.html) to read and `matplotlib` (https://matplotlib.org/gallery/index.html) to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: '/home/moucheng/harry/data/to_georgia/HCP/214019/T1w_acpc_dc_restore_brain.nii'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-404d7def2e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mproc_img_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/moucheng/harry/data/to_georgia/HCP/214019/T1w_acpc_dc_restore_brain_procin.nii'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgt_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_img_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mproc_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc_img_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/iqt/lib/python3.6/site-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     '''\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0msniff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_klass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_image_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/home/moucheng/harry/data/to_georgia/HCP/214019/T1w_acpc_dc_restore_brain.nii'"
     ]
    }
   ],
   "source": [
    "## Sample answer.\n",
    "\n",
    "# load the subject 200008\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# image file paths\n",
    "## gt=ground truth, proc = pre-processed\n",
    "gt_img_path = '/cs/student/msc/misc/2019/ucact21/hcp/HCP/214019/T1w_acpc_dc_restore_brain.nii'\n",
    "proc_img_path = '/cs/student/msc/misc/2019/ucact21/hcp/HCP/214019/T1w_acpc_dc_restore_brain_procin.nii'\n",
    "\n",
    "gt_img = nib.load(gt_img_path).get_data()\n",
    "proc_img = nib.load(proc_img_path).get_data()\n",
    "\n",
    "# Plot images in a 2x3 grid. Cross-sectional views by row w/o downsampling by column.\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(10*2, 10*2),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "fig.subplots_adjust(left=0.03, right=0.97, hspace=0.05, wspace=0.05)\n",
    "\n",
    "## Intersection of 3 viewing planes (axial/coronal/sagittal) \n",
    "# intersection coordinate at original image\n",
    "gt_intersect = [150, 150, 128]\n",
    "# sparse scale\n",
    "sparse_scale = gen_conf['dataset_info']['HCP-Wu-Minn-Contrast']['sparse_scale']\n",
    "apsect_ratio_scale = np.prod(sparse_scale)//np.array(sparse_scale)\n",
    "# intersection coordinate at processed image\n",
    "proc_intersect = np.array(gt_intersect)//np.array(sparse_scale)\n",
    "\n",
    "for idx, ax in enumerate(axs):\n",
    "    # initialisation\n",
    "    gt_coord = [slice(None), slice(None), slice(None)]\n",
    "    proc_coord = [slice(None), slice(None), slice(None)]\n",
    "    \n",
    "    # \n",
    "    gt_coord[idx] = slice(gt_intersect[idx], gt_intersect[idx]+1, 1)\n",
    "    proc_coord[idx] = slice(proc_intersect[idx], proc_intersect[idx]+1, 1)\n",
    "    \n",
    "    gt_reduced_img = np.squeeze(gt_img[gt_coord])\n",
    "    ax[0].imshow(gt_reduced_img.T, interpolation=None, cmap='gray', aspect=1, origin='lower')\n",
    "    \n",
    "    proc_reduced_img = np.squeeze(proc_img[proc_coord])\n",
    "    ax[1].imshow(proc_reduced_img.T, interpolation=None, cmap='gray', aspect=apsect_ratio_scale[idx], origin='lower')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test stage\n",
    "\n",
    "We provide a SRU-net pre-trained from the Human Connectome Project (HCP) dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from workflow.test import testing\n",
    "\n",
    "model = testing(gen_conf, train_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignments:\n",
    "\n",
    "1. Show summary of networks, which is saved in the variable `model` (Hint: Using `model.summary()` https://keras.io/models/about-keras-models/).\n",
    "2. Visualise the activation for each layer (Hint: https://keras.io/examples/conv_filter_visualization/).\n",
    "3. Use other datasets (e.g. HBN, IBSR) for predicting the network outputs.\n",
    "\n",
    "HBN: Child Mind Institute Healthy Brain Network http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/index.html\n",
    "\n",
    "IBSR: Internet Brain Segmentation Repository https://www.nitrc.org/projects/ibsr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluation metrics:\n",
    "1. PSNR: Peak Signal-to-Noise Ratio\n",
    "2. SSIM: Structural Similarity Index\n",
    "3. RMSE: Root Mean Squared Error\n",
    "\n",
    "### Assigments:\n",
    "1. Look at the evaluation result under `</task_name/>/evaluation/stats_brain.csv` and compare results from the different networks.\n",
    "2. Read the reference on SSIM, https://www.cns.nyu.edu/pub/lcv/wang03-preprint.pdf, and intuitively and/or theoretically explain if this index is suitable to MR image quality assessment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow.evaluation import evaluation\n",
    "\n",
    "evaluation(gen_conf, train_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
